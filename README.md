# Multi Modal Chat

Imagine a digital assistant that seamlessly works with text, images, PDFs, sounds and generates information based on the questions that we could have. Here is such an attempt. 

This project is all about integrating different AI models to handle audio, images, and PDFs in a single chat interface. A huge shout to [Leon Sander](https://www.youtube.com/@leonsaiagency) for holding an YouTube session that made things a lot simpler to understand and implement.

Audio-to-text yet to be implemented, is work in progress.

<!-- https://byby.dev/md-image-size -->
<center>
<img src="https://github.com/ra9hur/Multi-Modal-Chat/assets/17127066/d19fa767-582b-4986-aae3-a6ccc6894e9d" alt="image" width="500" height="auto">
</center>

<br>

![multi_modal](https://github.com/ra9hur/Multi-Modal-Chat/assets/17127066/92425935-95e8-4fa8-908f-1ab3373465a8)